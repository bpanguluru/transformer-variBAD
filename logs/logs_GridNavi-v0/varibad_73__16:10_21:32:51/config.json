{
  "num_frames": 20000000.0,
  "max_rollouts_per_task": 4,
  "exp_label": "varibad",
  "env_name": "GridNavi-v0",
  "pass_state_to_policy": true,
  "pass_latent_to_policy": true,
  "pass_belief_to_policy": false,
  "pass_task_to_policy": false,
  "policy_state_embedding_dim": 16,
  "policy_latent_embedding_dim": 16,
  "policy_belief_embedding_dim": null,
  "policy_task_embedding_dim": null,
  "norm_state_for_policy": true,
  "norm_latent_for_policy": true,
  "norm_belief_for_policy": true,
  "norm_task_for_policy": true,
  "norm_rew_for_policy": true,
  "norm_actions_pre_sampling": false,
  "norm_actions_post_sampling": false,
  "policy_layers": [
    32
  ],
  "policy_activation_function": "tanh",
  "policy_initialisation": "normc",
  "policy_anneal_lr": false,
  "policy": "ppo",
  "policy_optimiser": "adam",
  "ppo_num_epochs": 2,
  "ppo_num_minibatch": 4,
  "ppo_use_huberloss": true,
  "ppo_use_clipped_value_loss": true,
  "ppo_clip_param": 0.05,
  "lr_policy": 0.0007,
  "num_processes": 16,
  "policy_num_steps": 60,
  "policy_eps": 1e-08,
  "policy_init_std": 1.0,
  "policy_value_loss_coef": 0.5,
  "policy_entropy_coef": 0.01,
  "policy_gamma": 0.95,
  "policy_use_gae": true,
  "policy_tau": 0.95,
  "use_proper_time_limits": false,
  "policy_max_grad_norm": 0.5,
  "encoder_max_grad_norm": null,
  "decoder_max_grad_norm": null,
  "lr_vae": 0.001,
  "size_vae_buffer": 100000,
  "precollect_len": 5000,
  "vae_buffer_add_thresh": 1,
  "vae_batch_num_trajs": 25,
  "tbptt_stepsize": null,
  "vae_subsample_elbos": null,
  "vae_subsample_decodes": null,
  "vae_avg_elbo_terms": false,
  "vae_avg_reconstruction_terms": false,
  "num_vae_updates": 3,
  "pretrain_len": 0,
  "kl_weight": 0.01,
  "split_batches_by_task": false,
  "split_batches_by_elbo": false,
  "action_embedding_size": 0,
  "state_embedding_size": 8,
  "reward_embedding_size": 8,
  "encoder_layers_before_gru": [],
  "encoder_gru_hidden_size": 64,
  "encoder_layers_after_gru": [],
  "latent_dim": 5,
  "decode_reward": true,
  "rew_loss_coeff": 1.0,
  "input_prev_state": false,
  "input_action": false,
  "reward_decoder_layers": [
    32,
    32
  ],
  "multihead_for_reward": true,
  "rew_pred_type": "bernoulli",
  "decode_state": false,
  "state_loss_coeff": 1.0,
  "state_decoder_layers": [
    32,
    32
  ],
  "state_pred_type": "deterministic",
  "decode_task": false,
  "task_loss_coeff": 1.0,
  "task_decoder_layers": [
    32,
    32
  ],
  "task_pred_type": "task_id",
  "disable_decoder": false,
  "disable_stochasticity_in_latent": false,
  "disable_kl_term": false,
  "decode_only_past": false,
  "kl_to_gauss_prior": false,
  "rlloss_through_encoder": false,
  "add_nonlinearity_to_latent": false,
  "vae_loss_coeff": 1.0,
  "sample_embeddings": false,
  "disable_metalearner": false,
  "single_task_mode": false,
  "log_interval": 500,
  "save_interval": 1000,
  "save_intermediate_models": false,
  "eval_interval": 500,
  "vis_interval": 500,
  "results_log_dir": null,
  "seed": 73,
  "deterministic_execution": false,
  "action_space": null,
  "device": "cpu"
}